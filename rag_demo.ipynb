{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff4524e",
   "metadata": {},
   "source": [
    "### Import components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c89f7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.document_loader import load_pdf_document\n",
    "from src.chunking import chunk_text\n",
    "from src.embedding import Embedder\n",
    "from src.vector_store import FaissVectorStore\n",
    "from src.prompt_constructor import construct_prompt\n",
    "from src.lm import LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fe4e7",
   "metadata": {},
   "source": [
    "## Offline Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe64e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_DOCUMENT_PATH = r\"./data/document.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3d13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADED_DOCUMENT_PATH = r\"./data/document.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76db2e",
   "metadata": {},
   "source": [
    "### Load document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0901b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = load_pdf_document(PDF_DOCUMENT_PATH, LOADED_DOCUMENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072be49",
   "metadata": {},
   "source": [
    "### Chunk document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2af248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(LOADED_DOCUMENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9542a",
   "metadata": {},
   "source": [
    "### Embed document(s) chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc6250",
   "metadata": {},
   "source": [
    "Please install the following package:\n",
    "```bash\n",
    "pip install -U sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c9f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BAAI/bge-base-en-v1.5\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da0efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 9/9 [00:32<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "embedded_chunks = embedder.embed_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ac80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [chunk[\"embedding\"] for chunk in embedded_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2612c1",
   "metadata": {},
   "source": [
    "### Store vectors of embedded document(s) into a vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ba74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "faissVectorStore = FaissVectorStore(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e62bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "faissVectorStore.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba375f",
   "metadata": {},
   "source": [
    "## Online Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff10eb",
   "metadata": {},
   "source": [
    "### Embed user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f2cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Advanced RAG?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5e7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedder.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff56dd3",
   "metadata": {},
   "source": [
    "### Retrieve relevant chunks from the stored vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4f8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_chuncks = faissVectorStore.search(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b0072",
   "metadata": {},
   "source": [
    "### Construct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92fd4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = construct_prompt(query, retrieved_chuncks, embedded_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da05bd",
   "metadata": {},
   "source": [
    "### Generate answer with SLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783688d2",
   "metadata": {},
   "source": [
    "Please run the following commands in your terminal to access to huggingface models.\n",
    "\n",
    "```bash\n",
    "pip install huggingface_hub\n",
    "```\n",
    "\n",
    "After installing its package, please provide a token to login. \n",
    "\n",
    "You can create a token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "\n",
    "```bash\n",
    "huggingface-cli login\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d19758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Model: google/gemma-3-1b-it\n"
     ]
    }
   ],
   "source": [
    "lm = LM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78185956",
   "metadata": {},
   "source": [
    "Without RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147ae8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 7\n",
      "Context Window: 32768\n",
      "Max New Tokens: 128\n",
      "<bos>What is Advanced RAG?\n",
      "\n",
      "Advanced Retrieval-Augmented Generation (RAG) is a more sophisticated approach to large language models (LLMs) than traditional RAG. It goes beyond simply retrieving documents and instead actively weaves the retrieved information into the prompt to provide a more contextually relevant and accurate response.\n",
      "\n",
      "Here's a breakdown of key advancements and characteristics of Advanced RAG:**\n",
      "\n",
      "1. **Dynamic Retrieval:**\n",
      "   -  Instead of just storing documents in a vector database, Advanced RAG dynamically selects the most relevant passages based on the query.\n",
      "   -  This is achieved through techniques like:\n",
      "       - **Query Expansion:**  Expanding the\n"
     ]
    }
   ],
   "source": [
    "output = lm.generate_text(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe948644",
   "metadata": {},
   "source": [
    "With RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41e255f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 354\n",
      "Context Window: 32768\n",
      "Max New Tokens: 128\n",
      "<bos>\n",
      "You are an assistant.\n",
      "Answer the question using ONLY the provided context.\n",
      "The answer should be direct and compact.\n",
      "\n",
      "Context:\n",
      "[Chunk 30]\n",
      "_B. Advanced RAG_\n",
      "\n",
      "\n",
      "Advanced RAG introduces specific improvements to overcome the limitations of Naive RAG. Focusing on enhancing retrieval quality, it employs pre-retrieval and post-retrieval strategies. To tackle the indexing issues, Advanced RAG refines\n",
      "its indexing techniques through the use of a sliding window\n",
      "approach, fine-grained segmentation, and the incorporation of\n",
      "metadata. Additionally, it incorporates several optimization\n",
      "methods to streamline the retrieval process [8].\n",
      "\n",
      "[Chunk 20]\n",
      "The RAG research paradigm is continuously evolving, and\n",
      "we categorize it into three stages: Naive RAG, Advanced\n",
      "RAG, and Modular RAG, as showed in Figure 3. Despite\n",
      "RAG method are cost-effective and surpass the performance\n",
      "of the native LLM, they also exhibit several limitations.\n",
      "The development of Advanced RAG and Modular RAG is\n",
      "a response to these specific shortcomings in Naive RAG.\n",
      "\n",
      "[Chunk 32]\n",
      "Fig. 3. Comparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\n",
      "Advanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\n",
      "chain-like structure. (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall. This is evident in the\n",
      "\n",
      "\n",
      "\n",
      "Question:\n",
      "What is Advanced RAG?\n",
      "**Answer:**\n",
      "Advanced RAG introduces specific improvements to overcome the limitations of Naive RAG.\n",
      "\n",
      "**Explanation:**\n",
      "The context states that Advanced RAG improves retrieval quality. It employs pre-retrieval and post-retrieval strategies, refines indexing techniques, incorporates metadata, and uses a sliding window approach, all of which are designed to tackle limitations of Naive RAG.\n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "output = lm.generate_text(prompt)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
