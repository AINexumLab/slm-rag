{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff4524e",
   "metadata": {},
   "source": [
    "### Import components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c89f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.document_loader import load_pdf_document\n",
    "from src.chunking import chunk_text\n",
    "from src.embedding import Embedder\n",
    "from src.vector_store import FaissVectorStore\n",
    "from src.prompt_constructor import construct_prompt\n",
    "from src.lm import LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fe4e7",
   "metadata": {},
   "source": [
    "## Offline Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe64e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_DOCUMENT_PATH = r\"./data/document.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3d13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADED_DOCUMENT_PATH = r\"./data/document.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76db2e",
   "metadata": {},
   "source": [
    "### Load document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0901b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = load_pdf_document(PDF_DOCUMENT_PATH, LOADED_DOCUMENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072be49",
   "metadata": {},
   "source": [
    "### Chunk document(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2af248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(LOADED_DOCUMENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9542a",
   "metadata": {},
   "source": [
    "### Embed document(s) chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc6250",
   "metadata": {},
   "source": [
    "Please install the following package:\n",
    "```bash\n",
    "pip install -U sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c9f615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BAAI/bge-base-en-v1.5\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da0efce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c678096d34d4055a4177b94535c792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedded_chunks = embedder.embed_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ac80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [chunk[\"embedding\"] for chunk in embedded_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2612c1",
   "metadata": {},
   "source": [
    "### Store vectors of embedded document(s) into a vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ba74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "faissVectorStore = FaissVectorStore(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e62bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "faissVectorStore.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba375f",
   "metadata": {},
   "source": [
    "## Online Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff10eb",
   "metadata": {},
   "source": [
    "### Embed user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f2cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Advanced RAG?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5e7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedder.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff56dd3",
   "metadata": {},
   "source": [
    "### Retrieve relevant chunks from the stored vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4f8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_chuncks = faissVectorStore.search(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b0072",
   "metadata": {},
   "source": [
    "### Construct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92fd4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = construct_prompt(query, retrieved_chuncks, embedded_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da05bd",
   "metadata": {},
   "source": [
    "### Generate answer with SLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783688d2",
   "metadata": {},
   "source": [
    "Please run the following commands in your terminal to access to huggingface models.\n",
    "\n",
    "```bash\n",
    "pip install huggingface_hub\n",
    "```\n",
    "\n",
    "After installing its package, please provide a token to login. \n",
    "\n",
    "You can create a token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "\n",
    "```bash\n",
    "huggingface-cli login\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d19758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Model: google/gemma-3-1b-it\n"
     ]
    }
   ],
   "source": [
    "lm = LM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78185956",
   "metadata": {},
   "source": [
    "Without RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147ae8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 7\n",
      "Context Window: 32768\n",
      "Max New Tokens: 256\n",
      "<bos>What is Advanced RAG?\n",
      "\n",
      "Advanced RAG (Retrieval-Augmented Generation) goes beyond basic RAG by incorporating more sophisticated techniques to improve the accuracy, consistency, and usability of generated responses. It's essentially a layered approach combining retrieval and generation, improving the model's ability to understand context and deliver relevant answers.\n",
      "\n",
      "Here's a breakdown of key advancements in Advanced RAG:\n",
      "\n",
      "1.  **Memory Networks/Key-Value Stores:** These networks store and retrieve relevant information from both the input prompt and the retrieved context. This allows the model to explicitly \"remember\" key details and provide more contextually appropriate answers.\n",
      "\n",
      "2.  **Structured Context:** Going beyond just token-level context, Advanced RAG utilizes structured context like knowledge graphs or tables to represent information in a more organized way. This helps the model understand relationships between concepts.\n",
      "\n",
      "3.  **Dynamic Retrieval:** Instead of relying solely on the initial retrieval process, Advanced RAG dynamically adjusts the retrieval strategies based on the query and the context. This can involve incorporating multiple retrieval methods or using learned similarity scores.\n",
      "\n",
      "4.  **Multi-Hop Retrieval:**  The model is able to retrieve information from multiple sources simultaneously, improving its understanding and accuracy.\n",
      "\n",
      "5.  **Reinforcement Learning from Human Feedback\n"
     ]
    }
   ],
   "source": [
    "output = lm.generate_text(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe948644",
   "metadata": {},
   "source": [
    "With RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e255f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Length: 354\n",
      "Context Window: 32768\n",
      "Max New Tokens: 256\n",
      "<bos>\n",
      "You are an assistant.\n",
      "Answer the question using ONLY the provided context.\n",
      "The answer should be direct and compact.\n",
      "\n",
      "Context:\n",
      "[Chunk 30]\n",
      "_B. Advanced RAG_\n",
      "\n",
      "\n",
      "Advanced RAG introduces specific improvements to overcome the limitations of Naive RAG. Focusing on enhancing retrieval quality, it employs pre-retrieval and post-retrieval strategies. To tackle the indexing issues, Advanced RAG refines\n",
      "its indexing techniques through the use of a sliding window\n",
      "approach, fine-grained segmentation, and the incorporation of\n",
      "metadata. Additionally, it incorporates several optimization\n",
      "methods to streamline the retrieval process [8].\n",
      "\n",
      "[Chunk 20]\n",
      "The RAG research paradigm is continuously evolving, and\n",
      "we categorize it into three stages: Naive RAG, Advanced\n",
      "RAG, and Modular RAG, as showed in Figure 3. Despite\n",
      "RAG method are cost-effective and surpass the performance\n",
      "of the native LLM, they also exhibit several limitations.\n",
      "The development of Advanced RAG and Modular RAG is\n",
      "a response to these specific shortcomings in Naive RAG.\n",
      "\n",
      "[Chunk 32]\n",
      "Fig. 3. Comparison between the three paradigms of RAG. (Left) Naive RAG mainly consists of three parts: indexing, retrieval and generation. (Middle)\n",
      "Advanced RAG proposes multiple optimization strategies around pre-retrieval and post-retrieval, with a process similar to the Naive RAG, still following a\n",
      "chain-like structure. (Right) Modular RAG inherits and develops from the previous paradigm, showcasing greater flexibility overall. This is evident in the\n",
      "\n",
      "\n",
      "\n",
      "Question:\n",
      "What is Advanced RAG?\n",
      "Answer:\n",
      "Advanced RAG introduces specific improvements to overcome the limitations of Naive RAG.\n",
      "It employs pre-retrieval and post-retrieval strategies, refines indexing techniques through the use of a sliding window approach, incorporates metadata and optimization methods to streamline the retrieval process.\n",
      "Concise and direct.\n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "output = lm.generate_text(prompt)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
